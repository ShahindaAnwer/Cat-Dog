{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "zdzSMbvnCh1a",
        "S3RxFhkxFT4Q",
        "bhwtYmWsI1lT"
      ],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Packages**"
      ],
      "metadata": {
        "id": "X-lr7vrOJTR5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuxkhuxwgkfR"
      },
      "outputs": [],
      "source": [
        "#from __future__ import absolute_import, division, print_funtion, unicode_literals\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from IPython.display import Image\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras.models import Model\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import backend as k\n",
        "\n",
        "# import Dense and Activation Layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Flatten, Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# access drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HhqYwvIe_P7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ts = (256, 256)"
      ],
      "metadata": {
        "id": "nGELw_fV_y3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image Preprocessing:**"
      ],
      "metadata": {
        "id": "zdzSMbvnCh1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# apply transformations and zoom on images\n",
        "generated_train_data = ImageDataGenerator(\n",
        "    rotation_range = 40,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.5,\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True,\n",
        "    rescale = 1./255,\n",
        "    validation_split = 0.2\n",
        ") \n",
        "\n",
        "generated_val_data = ImageDataGenerator(rescale = 1./255) "
      ],
      "metadata": {
        "id": "zeX44AxOCW5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Loading Data**"
      ],
      "metadata": {
        "id": "S3RxFhkxFT4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = generated_train_data.flow_from_directory('/content/drive/MyDrive/ds', target_size = ts, color_mode = 'rgb', batch_size = 64, class_mode = 'categorical', subset = 'training')\n",
        "val_data = generated_train_data.flow_from_directory('/content/drive/MyDrive/ds', target_size = ts, color_mode = 'rgb', batch_size = 64, class_mode = 'categorical', subset = 'validation')"
      ],
      "metadata": {
        "id": "aAyAtRxAEEj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.image_shape"
      ],
      "metadata": {
        "id": "8rCa063oGzZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.class_indices"
      ],
      "metadata": {
        "id": "8iVUB44EIIAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create Model**"
      ],
      "metadata": {
        "id": "bhwtYmWsI1lT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, kernel_size = (3,3), input_shape = (256, 256, 3), activation = 'relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2), padding=\"same\"),\n",
        "    Conv2D(64, kernel_size = (5,5), input_shape = (256, 256, 3), activation = 'relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2), padding=\"same\"),\n",
        "    Conv2D(64, kernel_size = (5,5), input_shape = (256, 256, 3), activation = 'relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2), padding=\"same\"),\n",
        "    Conv2D(32, kernel_size = (5,5), input_shape = (256, 256, 3), activation = 'relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2), padding=\"same\"),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation = 'relu'),\n",
        "    Dense(64, activation = 'relu'),\n",
        "    Dropout(rate = 0.5),\n",
        "     Dense(2, activation = 'softmax'),\n",
        "])"
      ],
      "metadata": {
        "id": "8LbUWsf0I8lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img1 = image.load_img('/content/drive/MyDrive/ds/Cat/102.jpg')\n",
        "plt.imshow(img1)"
      ],
      "metadata": {
        "id": "kELNhikqKaV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img2 = image.load_img('/content/drive/MyDrive/ds/Dog/544.jpg')\n",
        "plt.imshow(img2)"
      ],
      "metadata": {
        "id": "prQD4ULZM3Uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training the Data**"
      ],
      "metadata": {
        "id": "SH72r_dpOz09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 30 # Epochs: number of passes of the entire training dataset the machine learning algorithm has completed\n",
        "LR = 1e-3 # Learning Rate: the step size taken at each iteration, moving towards the minimum of a loss function\n",
        "BS = 30 # Bach Size: number of training examples utilized in one iteration"
      ],
      "metadata": {
        "id": "55ydYWcXM6of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = \"binary_crossentropy\", optimizer = Adam(learning_rate = LR, decay = LR/ EPOCHS), metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "MA_EQ_oYQlVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "fmBBOEI_UAHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data,\n",
        "          steps_per_epoch = train_data.samples // train_data.batch_size,\n",
        "          epochs = 10,\n",
        "          validation_data = val_data,\n",
        "          validation_steps = val_data.samples // val_data.batch_size )"
      ],
      "metadata": {
        "id": "NllGEVOPUKII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model.save('catsvsdogs.h5')"
      ],
      "metadata": {
        "id": "-rTW_hrVay1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('catsvsdogsweights.h5')"
      ],
      "metadata": {
        "id": "DIfPtOHhMqXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.class_indices"
      ],
      "metadata": {
        "id": "MJC4WU3DMwKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data.class_indices"
      ],
      "metadata": {
        "id": "lasUB7ZYM6Sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['Cat', 'Dog']"
      ],
      "metadata": {
        "id": "2bizVivCQpIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing the Data**"
      ],
      "metadata": {
        "id": "Cx1QjJMQNaXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_width = 256\n",
        "img_height = 256\n",
        "\n",
        "from keras.preprocessing import image\n",
        "\n",
        "def prepare(img_path):\n",
        "  img = image.load_img(img_path, target_size = (256,256))\n",
        "  x = image.img_to_array(img)\n",
        "  x = x/255\n",
        "  return np.expand_dims(x, axis = 0)\n",
        "\n",
        "# print what animal the image shows\n",
        "result = model.predict([prepare('/content/11268.jpg')])\n",
        "classs=np.argmax(result ,axis=1)\n",
        "\n",
        "# show the image\n",
        "animal = image.load_img('/content/11268.jpg')\n",
        "plt.imshow(animal)\n",
        "print(classes[int(classs)])"
      ],
      "metadata": {
        "id": "tctsfrfDNfP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_width = 256\n",
        "img_height = 256\n",
        "\n",
        "from keras.preprocessing import image\n",
        "\n",
        "def prepare(img_path):\n",
        "  img = image.load_img(img_path, target_size = (256,256))\n",
        "  x = image.img_to_array(img)\n",
        "  x = x/255\n",
        "  return np.expand_dims(x, axis = 0)\n",
        "\n",
        "# print what animal the image shows\n",
        "result = model.predict([prepare('/content/12021.jpg')])\n",
        "classs=np.argmax(result ,axis=1)\n",
        "\n",
        "# show the image\n",
        "animal = image.load_img('/content/12021.jpg')\n",
        "plt.imshow(animal)\n",
        "print(classes[int(classs)])"
      ],
      "metadata": {
        "id": "RLVqiDoSPDYK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}